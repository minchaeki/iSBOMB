import OpenAI from "openai";
import { NextResponse } from "next/server";
import fs from "fs";
import path from "path";

export const runtime = "nodejs";

type Row = { id: string; title: string; chunk: string; embedding: number[] };

// â”€â”€ 0) ì¸ë±ìŠ¤ ë¡œë”© (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ)
let INDEX: Row[] = [];
(function loadIndex() {
  try {
    const idxPath = path.join(process.cwd(), "data", "mfds_index.json");
    const raw = fs.readFileSync(idxPath, "utf-8");
    INDEX = JSON.parse(raw) as Row[];
    console.log("ğŸ“š MFDS index loaded:", INDEX.length);
  } catch (e) {
    console.warn("âš ï¸ MFDS index not found. Run scripts/build_mfds_index.cjs first.");
    INDEX = [];
  }
})();

// â”€â”€ 1) ìœ í‹¸: ì½”ì‚¬ì¸ ìœ ì‚¬ë„
function cosine(a: number[], b: number[]) {
  let dot = 0, na = 0, nb = 0;
  for (let i = 0; i < a.length; i++) { dot += a[i] * b[i]; na += a[i]**2; nb += b[i]**2; }
  return dot / (Math.sqrt(na) * Math.sqrt(nb));
}

// â”€â”€ 2) ê²€ìƒ‰ í•¨ìˆ˜
async function retrieve(client: OpenAI, query: string, k = 4, minScore = 0.2) {
  if (!INDEX.length) return [];
  const emb = await client.embeddings.create({ model: "text-embedding-3-small", input: query });
  const qv = emb.data[0].embedding;
  return INDEX
    .map(r => ({ ...r, score: cosine(qv, r.embedding) }))
    .filter(s => s.score >= minScore)
    .sort((a, b) => b.score - a.score)
    .slice(0, k);
}

export async function POST(req: Request) {
  try {
    const { messages } = await req.json(); // [{role, content}, ...]
    const userMsg = Array.isArray(messages) ? messages.findLast((m: any) => m?.role === "user") : null;
    const userQ: string = userMsg?.content ?? "";

    const client = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY!,
      baseURL: process.env.OPENAI_BASE_URL || undefined,
    });

    // â”€â”€ 3) RAG ê²€ìƒ‰
    const hits = await retrieve(client, userQ, 4, 0.2);
    const context = hits.map(h => `### ${h.title}\n${h.chunk}`).join("\n\n---\n\n");

    // â”€â”€ 4) LLM í˜¸ì¶œ (ê·¼ê±° í¬í•¨)
    const system = [
      "ë„ˆëŠ” ì‹ì•½ì²˜ â€˜ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ ì˜ë£Œê¸°ê¸° í—ˆê°€Â·ì‹¬ì‚¬ ê°€ì´ë“œë¼ì¸â€™ ë³´ì¡°ì›ì´ë‹¤.",
      "ë°˜ë“œì‹œ ì•„ë˜ ì»¨í…ìŠ¤íŠ¸(ê°€ì´ë“œë¼ì¸ ë°œì·Œ)ì— ê·¼ê±°í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µí•´ë¼.",
      "ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ë³´ìˆ˜ì ìœ¼ë¡œ ë‹µí•˜ê³ , ë‹¨ì •ì  í‘œí˜„ì„ í”¼í•˜ë¼.",
      "ë‹µë³€ ëì— 'ê·¼ê±°' ì„¹ì…˜ìœ¼ë¡œ ì°¸ê³  ë¬¸ë‹¨(ì œëª©/ìª½)ì„ bulletë¡œ ìš”ì•½í•˜ë¼.",
    ].join(" ");

    const completion = await client.chat.completions.create({
      model: "gpt-4o-mini",
      temperature: 0.2,
      messages: [
        { role: "system", content: system },
        { role: "system", content: `ì»¨í…ìŠ¤íŠ¸(ê°€ì´ë“œë¼ì¸ ë°œì·Œ):\n${context || "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"}` },
        ...(Array.isArray(messages) ? messages : []),
      ],
    });

    const content = completion.choices[0]?.message?.content ?? "";
    return NextResponse.json({
      content,
      retrieved: hits.map(h => ({
        id: h.id,
        title: h.title,
        score: Number(h.score.toFixed(3)),
      })),
    });
  } catch (err: any) {
    console.error("/api/chat error:", err?.message || err);
    return NextResponse.json({ error: "Chat API error" }, { status: 500 });
  }
}